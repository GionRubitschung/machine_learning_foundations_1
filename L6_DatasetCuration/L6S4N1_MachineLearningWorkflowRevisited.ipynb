{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60645ad6",
   "metadata": {},
   "source": [
    "\n",
    "# Machine Learning Workflow Revisited\n",
    "\n",
    "In the initial notebooks of the course we introduced you to the machine learning workflow based on the `Iris` and `Digits` datasets.\n",
    "\n",
    "We know revisit the machine learning workflow and will dive a bit deeper into some of the aspects we covered in class. We will also start to work on datasets that you have created.\n",
    "This notebook provides an introduction to creating and evaluating a text classification model using the `scikit-learn` library. \n",
    "\n",
    "### Machine Learning Workflow\n",
    "\n",
    "The machine learning workflow as we know it involves the following steps:\n",
    "\n",
    "1. Dataset Curation\n",
    "2. Dataset Provisioning\n",
    "3. Model Training Run\n",
    "4. Evaluation\n",
    "5. Iterative Optimisation\n",
    "\n",
    "As a new element we will introduce text as input samples. All samples we have worked on before were based on features that were already numeric.\n",
    "With text as input we will have input that requires us to first consider how we transform the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9b63e",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Dataset Curation\n",
    "\n",
    "The data we will use are tweets collected from the UK around the time-frame of the original Brexit discussion.\n",
    "Please note that the data is not filtered in any way and might contain offensive content. \n",
    "\n",
    "The data has been annotated with two classes:\n",
    "* Brexit : tweets that relate to the topic Brexit\n",
    "* non-Brexit : tweets about other topics\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40aac43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of the dataframe are: Index(['tweet', 'label'], dtype='object').\n",
      "The shape of the dataframe is: (715, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>715</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>679</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>@_AnimalAdvocate she's one evil woman</td>\n",
       "      <td>non-Brexit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        tweet       label\n",
       "count                                     715         715\n",
       "unique                                    679           2\n",
       "top     @_AnimalAdvocate she's one evil woman  non-Brexit\n",
       "freq                                        6         700"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets_df = pd.read_csv(\"./cleaned_labeled_tweets.csv\")\n",
    "\n",
    "print(f\"The columns of the dataframe are: {tweets_df.columns}.\")\n",
    "print(f\"The shape of the dataframe is: {tweets_df.shape}\")\n",
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c890d9",
   "metadata": {},
   "source": [
    "### 1.1. Exercise: Explore the dataset\n",
    "\n",
    "Explore the dataset and get some familiarity by using the methods head(), tail().\n",
    "It is always recommendable to get `familiar` with the data.\n",
    "\n",
    "At a minimum you should verify that the data has loaded correctly via `read_csv()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203fe0d4",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Dataset Provisioning\n",
    "\n",
    "After loading the data we have to provision it. That is, we transform the data into the format required by the machine learning algorithm.\n",
    "We'll split our dataset into a training set and a testing set. The training set is used to train the model, and the testing set is used to evaluate its performance.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb7bc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets_df['tweet'], tweets_df['label'], test_size=0.2, random_state=42)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db17b9ad",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Model Training\n",
    "\n",
    "\n",
    "### 3.1 Create a Machine Learning Pipeline\n",
    "\n",
    "We create a pipeline that first converts the text data into a format suitable for machine learning (using `CountVectorizer`), and then applies a classification algorithm (in this case, `MultinomialNB`).\n",
    "\n",
    "The [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) in scikit-learn is a technique used to convert text input into numerical form. It involves several steps to transform textual data into a format that can be used for machine learning. The process includes:\n",
    "\n",
    "1. **Tokenization**: Splits text into individual words (tokens).\n",
    "2. **Text Cleaning**: Lowercasing, removing punctuation, and possibly removing stop words.\n",
    "3. **Building a Vocabulary**: Creates a list of all unique words from the entire text dataset.\n",
    "4. **Counting Occurrences**: Counts how many times each word appears in each document.\n",
    "5. **Vectorization**: Converts each document into a vector where each element represents the count of a word from the vocabulary in that document.\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa021fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Create a text processing and classification pipeline\n",
    "ml_pipeline = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22120645",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Train the Model\n",
    "\n",
    "With the pipeline set up, we can now train our model on the training data.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac80db1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "ml_pipeline.fit(X_train, y_train)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed634849",
   "metadata": {},
   "source": [
    "Two things happen when we execute the pipeline:\n",
    "\n",
    "1. **The CountVectorizer is fitted.**\n",
    "    * It cleans up all the text samples as described above\n",
    "    * It then identifies all unique terms that appear in the input dataset\n",
    "    * It stores those terms in a dictionary\n",
    "    * Finally it transforms the tweets into a vectorised form\n",
    "2. **The model is fitted (trained)**\n",
    "    * The vectorised tweets (by convention we call this `X`) and the labels (by convention we call this `y`) are passed to the ML model\n",
    "    * The ML model is trained \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa6680",
   "metadata": {},
   "source": [
    "### 3.3 Exercise: Exploring and Understanding the `CountVectorizer`\n",
    "\n",
    "Explore the `CountVectorizer`.\n",
    "\n",
    "Visit the documentation of the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) and find the appropriate ways to:\n",
    "\n",
    "1. Look at the vocabulary that resulted from the fitting process.\n",
    "    * Identify how many unique terms were contained\n",
    "    * Look at the kind of terms that is contained (you might be surprised at what is included)\n",
    "2. Identify the methods for encoding and decoding sample texts or sample tweets with the fitted vectoriser\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8988661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "['and this' 'document is' 'first document' 'is the' 'is this'\n",
      " 'second document' 'the first' 'the second' 'the third' 'third one'\n",
      " 'this document' 'this is' 'this the']\n",
      "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n",
      "column first\n",
      "vector: 1\n",
      "column is\n",
      "vector: 1\n",
      "column nice\n",
      "vector: 1\n",
      "column the\n",
      "vector: 1\n",
      "column this\n",
      "vector: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>nice</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first  is  nice  the  this\n",
       "0      1   1     1    1     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    " ]\n",
    "vectorizer1 = CountVectorizer()\n",
    "X = vectorizer1.fit_transform(corpus)\n",
    "print(vectorizer1.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "print(vectorizer2.get_feature_names_out())\n",
    "print(X2.toarray())\n",
    "\n",
    "vectorizer = ml_pipeline.steps[0][1]\n",
    "vectorized = vectorizer.transform([\"This is the first document. nice\"])\n",
    "vectorized_df = pd.DataFrame(vectorized.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "non_zero_entries = []\n",
    "for column in vectorized_df.columns:\n",
    "    if vectorized_df[[column]][column][0] > 0:\n",
    "        non_zero_entries.append(column)\n",
    "        print(f\"column {column}\")\n",
    "        print(f\"vector: {vectorized_df[[column]][column][0]}\")\n",
    "\n",
    "vectorized_df[non_zero_entries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f997a312",
   "metadata": {},
   "source": [
    "### 3.4 Questions\n",
    "\n",
    "Some questions to think about and discuss.\n",
    "\n",
    "1. What do you think about the method to transform the text into numerical form? Could there be a better way to do this kind of transformation? What would are potential problems that you can imagine that result from this approach?\n",
    "2. What happens if we encounter a term that is not part of the vocabulary of the CountVectorizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae5b3e",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Evaluation\n",
    "\n",
    "After training the model, we use it to make predictions on the test dataset.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e19b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict labels for the test set\n",
    "predictions = ml_pipeline.predict(X_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3efb93b",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Measure Precision\n",
    "Finally, we evaluate the model's performance by looking at its accuracy and a detailed classification report.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d39b5b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ee3901",
   "metadata": {},
   "source": [
    "### 4.2 Analysing Measurements\n",
    "\n",
    "What do you think about the measured accuracy?\n",
    "Are you satisfied with the model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ac1be",
   "metadata": {},
   "source": [
    "### 4.3 Exercise: Digging into the Metrics\n",
    "\n",
    "Scikit-learn provides several methods for analyzing the predictions of a model. Some of these methods include:\n",
    "\n",
    "1. **[Confusion Matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)**\n",
    "\n",
    "2. **[Classification Report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)**\n",
    "\n",
    "Use the above two methods to analyse the performance and discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d871ac2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Brexit       1.00      0.20      0.33         5\n",
      "  non-Brexit       0.97      1.00      0.99       138\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.99      0.60      0.66       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n",
      "[[  1   4]\n",
      " [  0 138]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
